{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc91691",
   "metadata": {},
   "source": [
    "# Exploring data and features\n",
    "\n",
    "## Core Features that could be added:\n",
    "\n",
    "### Price-Based Features:\n",
    "\n",
    "- Returns: 1-day, 3-day, 5-day, 10-day returns\n",
    "- Price ratios: Current price / MA(5), Current price / MA(20)\n",
    "- Gap features: (Open - Previous Close) / Previous Close\n",
    "- Intraday range: (High - Low) / Close\n",
    "\n",
    "### Volume Features:\n",
    "\n",
    "- Volume ratios: Current volume / MA(20 volume)\n",
    "- Price-volume: Return * Volume (captures momentum with conviction)\n",
    "\n",
    "### Technical Indicators:\n",
    "\n",
    "- RSI (14-day) - momentum oscillator\n",
    "- MACD signal (12,26,9) - trend following\n",
    "- Bollinger Band position: (Price - BB_lower) / (BB_upper - BB_lower)\n",
    "\n",
    "### Market Context:\n",
    "\n",
    "- VIX level (fear index)\n",
    "- Sector/market performance: Stock return vs S&P 500 return\n",
    "- Day of week dummy variables\n",
    "\n",
    "### Target Variable:\n",
    "\n",
    "- Binary: 1 if next day's close > today's close, 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d6f0f",
   "metadata": {},
   "source": [
    "# Load csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d671f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/interim/data_with_target.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d9fbbaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>WTI_Oil</th>\n",
       "      <th>US10Y</th>\n",
       "      <th>VIX</th>\n",
       "      <th>DJI</th>\n",
       "      <th>GSPC</th>\n",
       "      <th>NDX</th>\n",
       "      <th>RUT</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>72.538513</td>\n",
       "      <td>72.598892</td>\n",
       "      <td>71.292304</td>\n",
       "      <td>71.545890</td>\n",
       "      <td>135480400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>80580000</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>331.348572</td>\n",
       "      <td>331.378393</td>\n",
       "      <td>325.761816</td>\n",
       "      <td>326.606765</td>\n",
       "      <td>4544400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BAC</td>\n",
       "      <td>30.920326</td>\n",
       "      <td>30.937678</td>\n",
       "      <td>30.616677</td>\n",
       "      <td>30.668729</td>\n",
       "      <td>37614200</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BHP</td>\n",
       "      <td>33.608608</td>\n",
       "      <td>33.822793</td>\n",
       "      <td>33.522936</td>\n",
       "      <td>33.792196</td>\n",
       "      <td>1382193</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28929</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>T</td>\n",
       "      <td>22.028353</td>\n",
       "      <td>22.105747</td>\n",
       "      <td>21.863890</td>\n",
       "      <td>21.883239</td>\n",
       "      <td>22342800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28930</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>VTI</td>\n",
       "      <td>287.925415</td>\n",
       "      <td>290.240280</td>\n",
       "      <td>287.190237</td>\n",
       "      <td>289.912409</td>\n",
       "      <td>3893200</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28931</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>XOM</td>\n",
       "      <td>104.669357</td>\n",
       "      <td>104.990461</td>\n",
       "      <td>102.927624</td>\n",
       "      <td>103.307107</td>\n",
       "      <td>12387800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28932</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>4.573000</td>\n",
       "      <td>4.587000</td>\n",
       "      <td>4.521000</td>\n",
       "      <td>4.529000</td>\n",
       "      <td>0</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>^VIX</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>17.389999</td>\n",
       "      <td>0</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28934 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Ticker       Close        High         Low        Open  \\\n",
       "0      2020-01-02   AAPL   72.538513   72.598892   71.292304   71.545890   \n",
       "1      2020-01-02   AMZN   94.900497   94.900497   93.207497   93.750000   \n",
       "2      2020-01-02     BA  331.348572  331.378393  325.761816  326.606765   \n",
       "3      2020-01-02    BAC   30.920326   30.937678   30.616677   30.668729   \n",
       "4      2020-01-02    BHP   33.608608   33.822793   33.522936   33.792196   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "28929  2024-12-31      T   22.028353   22.105747   21.863890   21.883239   \n",
       "28930  2024-12-31    VTI  287.925415  290.240280  287.190237  289.912409   \n",
       "28931  2024-12-31    XOM  104.669357  104.990461  102.927624  103.307107   \n",
       "28932  2024-12-31   ^TNX    4.573000    4.587000    4.521000    4.529000   \n",
       "28933  2024-12-31   ^VIX   17.350000   17.809999   16.680000   17.389999   \n",
       "\n",
       "          Volume    WTI_Oil  US10Y    VIX           DJI         GSPC  \\\n",
       "0      135480400  61.180000  1.882  12.47  28868.800781  3257.850098   \n",
       "1       80580000  61.180000  1.882  12.47  28868.800781  3257.850098   \n",
       "2        4544400  61.180000  1.882  12.47  28868.800781  3257.850098   \n",
       "3       37614200  61.180000  1.882  12.47  28868.800781  3257.850098   \n",
       "4        1382193  61.180000  1.882  12.47  28868.800781  3257.850098   \n",
       "...          ...        ...    ...    ...           ...          ...   \n",
       "28929   22342800  71.720001  4.573  17.35  42544.218750  5881.629883   \n",
       "28930    3893200  71.720001  4.573  17.35  42544.218750  5881.629883   \n",
       "28931   12387800  71.720001  4.573  17.35  42544.218750  5881.629883   \n",
       "28932          0  71.720001  4.573  17.35  42544.218750  5881.629883   \n",
       "28933          0  71.720001  4.573  17.35  42544.218750  5881.629883   \n",
       "\n",
       "                NDX          RUT  Target  \n",
       "0       8872.219727  1666.770020       0  \n",
       "1       8872.219727  1666.770020       0  \n",
       "2       8872.219727  1666.770020       1  \n",
       "3       8872.219727  1666.770020       0  \n",
       "4       8872.219727  1666.770020       0  \n",
       "...             ...          ...     ...  \n",
       "28929  21012.169922  2230.159912       1  \n",
       "28930  21012.169922  2230.159912       1  \n",
       "28931  21012.169922  2230.159912       1  \n",
       "28932  21012.169922  2230.159912       1  \n",
       "28933  21012.169922  2230.159912       1  \n",
       "\n",
       "[28934 rows x 15 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35607ac",
   "metadata": {},
   "source": [
    "# Add features\n",
    "Doing this before one-hot encoding stocks will make it easier for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe314b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_tickers = ['VIX', 'WTI_Oil', 'US10Y']  # VIX, WTI Oil, 10Y Treasury\n",
    "\n",
    "data['VIX_ret'] = data['VIX'].pct_change()\n",
    "data['WTI_ret'] = data['WTI_Oil'].pct_change()\n",
    "data['TNX_ret'] = data['US10Y'].pct_change()\n",
    "\n",
    "data['VIX_5d_mean'] = data['VIX'].rolling(5).mean()\n",
    "data['WTI_5d_std'] = data['WTI_Oil'].rolling(5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7095ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_indices = [\"GSPC\", \"NDX\", \"RUT\", \"DJI\"]\n",
    "\n",
    "for idx in market_indices:\n",
    "    data[f'{idx}_return_1d'] = data[idx].pct_change()\n",
    "    data[f'{idx}_return_5d'] = data[idx].pct_change(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5b2a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "data['return_1d'] = data.groupby('Ticker')['Close'].pct_change()\n",
    "data['return_3d'] = data.groupby('Ticker')['Close'].pct_change(3)\n",
    "data['return_5d'] = data.groupby('Ticker')['Close'].pct_change(5)\n",
    "data['return_10d'] = data.groupby('Ticker')['Close'].pct_change(10)\n",
    "\n",
    "data['rolling_std_5'] = data['Close'].rolling(window=5).std()\n",
    "data['rolling_std_10'] = data['Close'].rolling(window=10).std()\n",
    "\n",
    "data['ma_5'] = data.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=5).mean())\n",
    "data['ma_20'] = data.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=20).mean())\n",
    "\n",
    "data['price_ma5_ratio'] = data['Close'] / data['ma_5']\n",
    "data['price_ma20_ratio'] = data['Close'] / data['ma_20']\n",
    "\n",
    "data['volume_ratio'] = (\n",
    "    data['Volume'] / \n",
    "    data.groupby('Ticker')['Volume'].transform(lambda x: x.rolling(20).mean())\n",
    ")\n",
    "\n",
    "data['price_volume'] = data['return_1d'] * data['Volume']\n",
    "\n",
    "data['rsi'] = data.groupby('Ticker')['Close'].transform(\n",
    "    lambda x: talib.RSI(x.values, timeperiod=14)\n",
    ")\n",
    "\n",
    "data['macd'] = data.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean() - x.ewm(span=26, adjust=False).mean())\n",
    "data['macd_signal'] = data.groupby('Ticker')['macd'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "data['macd_hist'] = data['macd'] - data['macd_signal'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c9cc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Range\n",
    "data['tr'] = data['High'] - data['Low']\n",
    "data['tr1'] = abs(data['High'] - data['Close'].shift(1))\n",
    "data['tr2'] = abs(data['Low'] - data['Close'].shift(1))\n",
    "data['true_range'] = data[['tr','tr1','tr2']].max(axis=1)\n",
    "\n",
    "# ATR with 14-day window\n",
    "data['ATR_14'] = data['true_range'].rolling(window=14).mean()\n",
    "\n",
    "# Drop intermediate columns\n",
    "data.drop(columns=['tr','tr1','tr2','true_range'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 20-day moving average\n",
    "data['MA20'] = data['Close'].rolling(window=20).mean()\n",
    "# 20-day standard deviation\n",
    "data['STD20'] = data['Close'].rolling(window=20).std()\n",
    "\n",
    "# Upper & lower bands\n",
    "data['BB_upper'] = data['MA20'] + (2 * data['STD20'])\n",
    "data['BB_lower'] = data['MA20'] - (2 * data['STD20'])\n",
    "\n",
    "# Bandwidth (upper - lower) / moving average\n",
    "data['BB_width'] = (data['BB_upper'] - data['BB_lower']) / data['MA20']\n",
    "\n",
    "# Optional: drop intermediate columns\n",
    "data.drop(columns=['MA20','STD20','BB_upper','BB_lower'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1a63a840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_WTI_Oil</th>\n",
       "      <th>Close_US10Y</th>\n",
       "      <th>Close_VIX</th>\n",
       "      <th>...</th>\n",
       "      <th>ma_5</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>price_ma5_ratio</th>\n",
       "      <th>price_ma20_ratio</th>\n",
       "      <th>volume_ratio</th>\n",
       "      <th>price_volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>72.538513</td>\n",
       "      <td>72.598892</td>\n",
       "      <td>71.292304</td>\n",
       "      <td>71.545890</td>\n",
       "      <td>135480400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>80580000</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>331.348572</td>\n",
       "      <td>331.378393</td>\n",
       "      <td>325.761816</td>\n",
       "      <td>326.606765</td>\n",
       "      <td>4544400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BAC</td>\n",
       "      <td>30.920328</td>\n",
       "      <td>30.937680</td>\n",
       "      <td>30.616679</td>\n",
       "      <td>30.668731</td>\n",
       "      <td>37614200</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>BHP</td>\n",
       "      <td>33.608612</td>\n",
       "      <td>33.822797</td>\n",
       "      <td>33.522940</td>\n",
       "      <td>33.792200</td>\n",
       "      <td>1382193</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28929</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>T</td>\n",
       "      <td>22.028353</td>\n",
       "      <td>22.105747</td>\n",
       "      <td>21.863890</td>\n",
       "      <td>21.883239</td>\n",
       "      <td>22342800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>22.086399</td>\n",
       "      <td>22.385818</td>\n",
       "      <td>0.997372</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>0.615997</td>\n",
       "      <td>158107.574053</td>\n",
       "      <td>47.674542</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>0.055084</td>\n",
       "      <td>-0.075379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28930</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>VTI</td>\n",
       "      <td>287.925415</td>\n",
       "      <td>290.240280</td>\n",
       "      <td>287.190237</td>\n",
       "      <td>289.912409</td>\n",
       "      <td>3893200</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>291.911316</td>\n",
       "      <td>294.711401</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>1.229428</td>\n",
       "      <td>-13520.654188</td>\n",
       "      <td>40.698731</td>\n",
       "      <td>-0.552695</td>\n",
       "      <td>0.457792</td>\n",
       "      <td>-1.010487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28931</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>XOM</td>\n",
       "      <td>104.669365</td>\n",
       "      <td>104.990468</td>\n",
       "      <td>102.927632</td>\n",
       "      <td>103.307115</td>\n",
       "      <td>12387800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>103.667140</td>\n",
       "      <td>106.728794</td>\n",
       "      <td>1.009668</td>\n",
       "      <td>0.980704</td>\n",
       "      <td>0.723517</td>\n",
       "      <td>212006.506014</td>\n",
       "      <td>34.801201</td>\n",
       "      <td>-2.795823</td>\n",
       "      <td>-2.806249</td>\n",
       "      <td>0.010427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28932</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>4.573000</td>\n",
       "      <td>4.587000</td>\n",
       "      <td>4.521000</td>\n",
       "      <td>4.529000</td>\n",
       "      <td>0</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>4.581400</td>\n",
       "      <td>4.401200</td>\n",
       "      <td>0.998166</td>\n",
       "      <td>1.039035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.362347</td>\n",
       "      <td>0.086270</td>\n",
       "      <td>0.070208</td>\n",
       "      <td>0.016062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28933</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>^VIX</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>17.389999</td>\n",
       "      <td>0</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>15.940000</td>\n",
       "      <td>15.992500</td>\n",
       "      <td>1.088457</td>\n",
       "      <td>1.084884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>52.091724</td>\n",
       "      <td>0.336709</td>\n",
       "      <td>0.285328</td>\n",
       "      <td>0.051381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28934 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Ticker       Close        High         Low        Open  \\\n",
       "0      2020-01-02   AAPL   72.538513   72.598892   71.292304   71.545890   \n",
       "1      2020-01-02   AMZN   94.900497   94.900497   93.207497   93.750000   \n",
       "2      2020-01-02     BA  331.348572  331.378393  325.761816  326.606765   \n",
       "3      2020-01-02    BAC   30.920328   30.937680   30.616679   30.668731   \n",
       "4      2020-01-02    BHP   33.608612   33.822797   33.522940   33.792200   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "28929  2024-12-31      T   22.028353   22.105747   21.863890   21.883239   \n",
       "28930  2024-12-31    VTI  287.925415  290.240280  287.190237  289.912409   \n",
       "28931  2024-12-31    XOM  104.669365  104.990468  102.927632  103.307115   \n",
       "28932  2024-12-31   ^TNX    4.573000    4.587000    4.521000    4.529000   \n",
       "28933  2024-12-31   ^VIX   17.350000   17.809999   16.680000   17.389999   \n",
       "\n",
       "          Volume  Close_WTI_Oil  Close_US10Y  Close_VIX  ...        ma_5  \\\n",
       "0      135480400      61.180000        1.882      12.47  ...         NaN   \n",
       "1       80580000      61.180000        1.882      12.47  ...         NaN   \n",
       "2        4544400      61.180000        1.882      12.47  ...         NaN   \n",
       "3       37614200      61.180000        1.882      12.47  ...         NaN   \n",
       "4        1382193      61.180000        1.882      12.47  ...         NaN   \n",
       "...          ...            ...          ...        ...  ...         ...   \n",
       "28929   22342800      71.720001        4.573      17.35  ...   22.086399   \n",
       "28930    3893200      71.720001        4.573      17.35  ...  291.911316   \n",
       "28931   12387800      71.720001        4.573      17.35  ...  103.667140   \n",
       "28932          0      71.720001        4.573      17.35  ...    4.581400   \n",
       "28933          0      71.720001        4.573      17.35  ...   15.940000   \n",
       "\n",
       "            ma_20  price_ma5_ratio  price_ma20_ratio  volume_ratio  \\\n",
       "0             NaN              NaN               NaN           NaN   \n",
       "1             NaN              NaN               NaN           NaN   \n",
       "2             NaN              NaN               NaN           NaN   \n",
       "3             NaN              NaN               NaN           NaN   \n",
       "4             NaN              NaN               NaN           NaN   \n",
       "...           ...              ...               ...           ...   \n",
       "28929   22.385818         0.997372          0.984032      0.615997   \n",
       "28930  294.711401         0.986346          0.976974      1.229428   \n",
       "28931  106.728794         1.009668          0.980704      0.723517   \n",
       "28932    4.401200         0.998166          1.039035           NaN   \n",
       "28933   15.992500         1.088457          1.084884           NaN   \n",
       "\n",
       "        price_volume        rsi      macd  macd_signal  macd_hist  \n",
       "0                NaN        NaN  0.000000     0.000000   0.000000  \n",
       "1                NaN        NaN  0.000000     0.000000   0.000000  \n",
       "2                NaN        NaN  0.000000     0.000000   0.000000  \n",
       "3                NaN        NaN  0.000000     0.000000   0.000000  \n",
       "4                NaN        NaN  0.000000     0.000000   0.000000  \n",
       "...              ...        ...       ...          ...        ...  \n",
       "28929  158107.574053  47.674542 -0.020294     0.055084  -0.075379  \n",
       "28930  -13520.654188  40.698731 -0.552695     0.457792  -1.010487  \n",
       "28931  212006.506014  34.801201 -2.795823    -2.806249   0.010427  \n",
       "28932       0.000000  63.362347  0.086270     0.070208   0.016062  \n",
       "28933      -0.000000  52.091724  0.336709     0.285328   0.051381  \n",
       "\n",
       "[28934 rows x 30 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6219f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode stock symbols (will need to normalize features within each stock \n",
    "# to account for different scales instead when adding more stocks to dataset)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_values = encoder.fit_transform(data[['Ticker']])\n",
    "new_cols = encoder.get_feature_names_out(['Ticker'])\n",
    "\n",
    "df_encoded = pd.DataFrame(encoded_values, columns=new_cols, index=data.index)\n",
    "\n",
    "df = pd.concat(\n",
    "    [data.drop(columns=['Ticker']), df_encoded],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b11ad633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>WTI_Oil</th>\n",
       "      <th>US10Y</th>\n",
       "      <th>VIX</th>\n",
       "      <th>DJI</th>\n",
       "      <th>GSPC</th>\n",
       "      <th>NDX</th>\n",
       "      <th>RUT</th>\n",
       "      <th>Target</th>\n",
       "      <th>VIX_ret</th>\n",
       "      <th>WTI_ret</th>\n",
       "      <th>TNX_ret</th>\n",
       "      <th>VIX_5d_mean</th>\n",
       "      <th>WTI_5d_std</th>\n",
       "      <th>GSPC_return_1d</th>\n",
       "      <th>GSPC_return_5d</th>\n",
       "      <th>NDX_return_1d</th>\n",
       "      <th>NDX_return_5d</th>\n",
       "      <th>RUT_return_1d</th>\n",
       "      <th>RUT_return_5d</th>\n",
       "      <th>DJI_return_1d</th>\n",
       "      <th>DJI_return_5d</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_5d</th>\n",
       "      <th>return_10d</th>\n",
       "      <th>ma_5</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>price_ma5_ratio</th>\n",
       "      <th>price_ma20_ratio</th>\n",
       "      <th>volume_ratio</th>\n",
       "      <th>price_volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>BB_width</th>\n",
       "      <th>Ticker_AAPL</th>\n",
       "      <th>Ticker_AMZN</th>\n",
       "      <th>Ticker_BA</th>\n",
       "      <th>Ticker_BAC</th>\n",
       "      <th>Ticker_BHP</th>\n",
       "      <th>Ticker_DIS</th>\n",
       "      <th>Ticker_GOOG</th>\n",
       "      <th>Ticker_IWM</th>\n",
       "      <th>Ticker_JNJ</th>\n",
       "      <th>Ticker_JPM</th>\n",
       "      <th>Ticker_KO</th>\n",
       "      <th>Ticker_MSFT</th>\n",
       "      <th>Ticker_NEE</th>\n",
       "      <th>Ticker_NVDA</th>\n",
       "      <th>Ticker_PFE</th>\n",
       "      <th>Ticker_QQQ</th>\n",
       "      <th>Ticker_SPY</th>\n",
       "      <th>Ticker_T</th>\n",
       "      <th>Ticker_VTI</th>\n",
       "      <th>Ticker_XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>72.538521</td>\n",
       "      <td>72.598899</td>\n",
       "      <td>71.292311</td>\n",
       "      <td>71.545897</td>\n",
       "      <td>135480400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>80580000</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>331.348572</td>\n",
       "      <td>331.378393</td>\n",
       "      <td>325.761816</td>\n",
       "      <td>326.606765</td>\n",
       "      <td>4544400</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>30.920332</td>\n",
       "      <td>30.937684</td>\n",
       "      <td>30.616682</td>\n",
       "      <td>30.668735</td>\n",
       "      <td>37614200</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>33.608608</td>\n",
       "      <td>33.822793</td>\n",
       "      <td>33.522936</td>\n",
       "      <td>33.792196</td>\n",
       "      <td>1382193</td>\n",
       "      <td>61.180000</td>\n",
       "      <td>1.882</td>\n",
       "      <td>12.47</td>\n",
       "      <td>28868.800781</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>1666.770020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25155</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>509.896118</td>\n",
       "      <td>516.309303</td>\n",
       "      <td>508.928648</td>\n",
       "      <td>515.551337</td>\n",
       "      <td>29117000</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.034686</td>\n",
       "      <td>-0.022262</td>\n",
       "      <td>-0.048527</td>\n",
       "      <td>520.430530</td>\n",
       "      <td>521.716696</td>\n",
       "      <td>0.979758</td>\n",
       "      <td>0.977343</td>\n",
       "      <td>0.966919</td>\n",
       "      <td>-247340.540242</td>\n",
       "      <td>44.908909</td>\n",
       "      <td>2.612441</td>\n",
       "      <td>4.733597</td>\n",
       "      <td>-2.121156</td>\n",
       "      <td>149.444374</td>\n",
       "      <td>3.284233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25156</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>582.599915</td>\n",
       "      <td>587.132835</td>\n",
       "      <td>580.949738</td>\n",
       "      <td>586.407129</td>\n",
       "      <td>57052700</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003638</td>\n",
       "      <td>-0.025377</td>\n",
       "      <td>-0.014478</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>590.860559</td>\n",
       "      <td>594.672549</td>\n",
       "      <td>0.986019</td>\n",
       "      <td>0.979699</td>\n",
       "      <td>1.110222</td>\n",
       "      <td>-207559.756570</td>\n",
       "      <td>41.593611</td>\n",
       "      <td>-0.428328</td>\n",
       "      <td>1.330239</td>\n",
       "      <td>-1.758567</td>\n",
       "      <td>151.849140</td>\n",
       "      <td>3.280292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25157</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>22.028353</td>\n",
       "      <td>22.105747</td>\n",
       "      <td>21.863890</td>\n",
       "      <td>21.883239</td>\n",
       "      <td>22342800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>-0.008275</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>22.086398</td>\n",
       "      <td>22.385818</td>\n",
       "      <td>0.997372</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>0.615997</td>\n",
       "      <td>158109.536105</td>\n",
       "      <td>47.674544</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>0.055084</td>\n",
       "      <td>-0.075379</td>\n",
       "      <td>182.326182</td>\n",
       "      <td>3.279977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25158</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>287.925415</td>\n",
       "      <td>290.240280</td>\n",
       "      <td>287.190237</td>\n",
       "      <td>289.912409</td>\n",
       "      <td>3893200</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>-0.025161</td>\n",
       "      <td>-0.014252</td>\n",
       "      <td>-0.034558</td>\n",
       "      <td>291.911316</td>\n",
       "      <td>294.711401</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>1.229428</td>\n",
       "      <td>-13520.654188</td>\n",
       "      <td>40.698730</td>\n",
       "      <td>-0.552695</td>\n",
       "      <td>0.457792</td>\n",
       "      <td>-1.010487</td>\n",
       "      <td>201.123388</td>\n",
       "      <td>3.280165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25159</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>104.669365</td>\n",
       "      <td>104.990468</td>\n",
       "      <td>102.927632</td>\n",
       "      <td>103.307115</td>\n",
       "      <td>12387800</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>4.573</td>\n",
       "      <td>17.35</td>\n",
       "      <td>42544.218750</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>21012.169922</td>\n",
       "      <td>2230.159912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.010142</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>-0.008297</td>\n",
       "      <td>103.667142</td>\n",
       "      <td>106.728794</td>\n",
       "      <td>1.009668</td>\n",
       "      <td>0.980704</td>\n",
       "      <td>0.723517</td>\n",
       "      <td>212006.506014</td>\n",
       "      <td>34.801215</td>\n",
       "      <td>-2.795822</td>\n",
       "      <td>-2.806249</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>209.819697</td>\n",
       "      <td>3.277583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25160 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Close        High  ...  Ticker_T  Ticker_VTI  Ticker_XOM\n",
       "0      2020-01-02   72.538521   72.598899  ...       0.0         0.0         0.0\n",
       "1      2020-01-02   94.900497   94.900497  ...       0.0         0.0         0.0\n",
       "2      2020-01-02  331.348572  331.378393  ...       0.0         0.0         0.0\n",
       "3      2020-01-02   30.920332   30.937684  ...       0.0         0.0         0.0\n",
       "4      2020-01-02   33.608608   33.822793  ...       0.0         0.0         0.0\n",
       "...           ...         ...         ...  ...       ...         ...         ...\n",
       "25155  2024-12-31  509.896118  516.309303  ...       0.0         0.0         0.0\n",
       "25156  2024-12-31  582.599915  587.132835  ...       0.0         0.0         0.0\n",
       "25157  2024-12-31   22.028353   22.105747  ...       1.0         0.0         0.0\n",
       "25158  2024-12-31  287.925415  290.240280  ...       0.0         1.0         0.0\n",
       "25159  2024-12-31  104.669365  104.990468  ...       0.0         0.0         1.0\n",
       "\n",
       "[25160 rows x 63 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60dfa1",
   "metadata": {},
   "source": [
    "# Handle NaNs\n",
    "\n",
    "XGBoost can handle NaNs in features, except in the target variable. For now I will fill them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d9d60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab49e0",
   "metadata": {},
   "source": [
    "# Split training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b033c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"NVDA\", \"JPM\", \"BAC\", \"JNJ\", \"PFE\", \"DIS\", \"KO\", \"BA\", \"XOM\", \"BHP\", \"NEE\", \"T\", \"SPY\", \"QQQ\", \"IWM\", \"VTI\"]\n",
    "ticker_columns = [col for col in df.columns if col.startswith('Ticker_')]\n",
    "macro_features = ['VIX_ret', 'WTI_ret', 'TNX_ret', 'VIX_5d_mean', 'WTI_5d_std']\n",
    "feature_columns = ['return_1d', 'return_3d', 'return_5d', 'volume_ratio', 'rsi', 'macd', 'macd_hist', 'price_ma5_ratio', 'price_ma20_ratio', 'price_volume', 'rolling_std_5', 'rolling_std_10', 'ATR_14', 'BB_width'] + ticker_columns + macro_features\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161c4cc",
   "metadata": {},
   "source": [
    "# Check for class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "660b87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set class distribution:\n",
      "Class -1: 43.6%, Class 0: 6.3%, Class 1: 50.1%\n",
      "\n",
      "Test set class distribution:\n",
      "Class -1: 39.6%, Class 0: 9.1%, Class 1: 51.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining set class distribution:\")\n",
    "train_counts = y_train.value_counts(normalize=True)\n",
    "print(f\"Class -1: {train_counts.get(0, 0):.1%}, \"\n",
    "      f\"Class 0: {train_counts.get(1, 0):.1%}, \"\n",
    "      f\"Class 1: {train_counts.get(2, 0):.1%}\")\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "test_counts = y_test.value_counts(normalize=True)\n",
    "print(f\"Class -1: {test_counts.get(0, 0):.1%}, \"\n",
    "      f\"Class 0: {test_counts.get(1, 0):.1%}, \"\n",
    "      f\"Class 1: {test_counts.get(2, 0):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16923e",
   "metadata": {},
   "source": [
    "## Calculate class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ed167f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {2: 0.6652784663691952, 0: 0.7641609719058466, 1: 5.312219583003431}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_counts = y_train.value_counts().to_dict()\n",
    "n_total = len(y_train)\n",
    "n_classes = len(class_counts)\n",
    "\n",
    "# Compute weights\n",
    "class_weights = {cls: n_total / (count * n_classes) for cls, count in class_counts.items()}\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e48417",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a53dd",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244cf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     22\u001b[39m tscv = TimeSeriesSplit(n_splits=\u001b[32m3\u001b[39m)\n\u001b[32m     24\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m     25\u001b[39m     xgb, \n\u001b[32m     26\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, random_search.best_params_)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest score:\u001b[39m\u001b[33m\"\u001b[39m, random_search.best_score_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from scipy.stats import uniform, randint\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Need TimeSeriesSplit for financial data\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=tscv,\n",
    "    verbose=1, \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "print(\"Best score:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ef682",
   "metadata": {},
   "source": [
    "## Feature selection based on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34971cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m y1_pred = model.predict(X1_test)\n\u001b[32m     34\u001b[39m tscv = TimeSeriesSplit(n_splits=\u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtscv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbalanced_accuracy_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAdded features: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(ft))\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBalanced CV Accuracy:\u001b[39m\u001b[33m'\u001b[39m, scores.mean())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1683\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1661\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1662\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1663\u001b[39m )\n\u001b[32m   1664\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1665\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1666\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1680\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1681\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1683\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "\n",
    "base_features = feature_columns\n",
    "candidate_feature_sets =  [[], ['VIX_5d_mean', 'WTI_5d_std']]\n",
    "\n",
    "for ft in candidate_feature_sets:\n",
    "    model = XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "\n",
    "        # Obtained from hyperparameter tuning\n",
    "        subsample=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0,\n",
    "        n_estimators=100,\n",
    "        min_child_weight=5,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "\n",
    "    X1 = df[base_features + ft]\n",
    "    y1 = df['Target']\n",
    "\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, shuffle=False)\n",
    "\n",
    "    weights = y1_train.map(class_weights)\n",
    "\n",
    "    model.fit(X1_train, y1_train, sample_weight=weights)\n",
    "\n",
    "    y1_pred = model.predict(X1_test)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    scores = cross_val_score(model, X1, y1, cv=tscv,\n",
    "                                scoring=make_scorer(balanced_accuracy_score))\n",
    "    print('Added features: ' + str(ft))\n",
    "    print('Balanced CV Accuracy:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5033147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "\n",
    "    n_estimators=300,         # more boosting rounds\n",
    "    learning_rate=0.15,       # smaller learning rate\n",
    "    max_depth=5,              # control overfitting\n",
    "    min_child_weight=1,       # minimum data per leaf\n",
    "    subsample=0.8,            # row sampling\n",
    "    colsample_bytree=0.8,     # feature sampling\n",
    "    gamma=1,                  # regularization for splits\n",
    "    reg_lambda=2 \n",
    ")\n",
    "\n",
    "weights = y_train.map(class_weights)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe06722",
   "metadata": {},
   "source": [
    "## Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2de5d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4344\n",
      "Balanced CV Accuracy: 0.3376\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.39      0.40      1995\n",
      "        Flat       0.10      0.09      0.09       457\n",
      "          Up       0.51      0.53      0.52      2580\n",
      "\n",
      "    accuracy                           0.43      5032\n",
      "   macro avg       0.34      0.34      0.34      5032\n",
      "weighted avg       0.43      0.43      0.43      5032\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Basic accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Balanced CV Accuracy\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "scores = cross_val_score(\n",
    "    model, X, y, cv=tscv, scoring=make_scorer(balanced_accuracy_score)\n",
    ")\n",
    "print(f\"Balanced CV Accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Down\", \"Flat\", \"Up\"]))\n",
    "\n",
    "# Confusion Matrix with labels\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Down\", \"Flat\", \"Up\"],\n",
    "            yticklabels=[\"Down\", \"Flat\", \"Up\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c8e22",
   "metadata": {},
   "source": [
    "## Feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "29692f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return feature correlations:\n",
      "           return_1d  return_3d  return_5d\n",
      "return_1d   1.000000   0.649080   0.522679\n",
      "return_3d   0.649080   1.000000   0.769008\n",
      "return_5d   0.522679   0.769008   1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check correlation between your return features\n",
    "return_features = ['return_1d', 'return_3d', 'return_5d']\n",
    "correlation_matrix = X_train[return_features].corr()\n",
    "\n",
    "print(\"Return feature correlations:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Return Feature Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de408572",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "2e40abaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[325]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m feature_names = X_train.columns\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create importance DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m importance_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimportance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_importance\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.sort_values(\u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop 10 Most Important Features:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(importance_df.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\maria\\stock-movement-prediction-ml\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance_df.head(10).plot(x='feature', y='importance', kind='bar')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4542b3",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8487abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m tscv = TimeSeriesSplit(n_splits=\u001b[32m5\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Cross-validation scores\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m cv_scores = cross_val_score(\u001b[43mmodel\u001b[49m, X_train, y_train, cv=tscv, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross-validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean CV accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "# Use TimeSeriesSplit for financial data (respects temporal order)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
